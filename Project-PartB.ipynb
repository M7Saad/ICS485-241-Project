{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part-B, Active Learning\n",
        "\n",
        "- used resources:\n",
        "\n",
        "  1 - https://scikit-learn.org/stable/auto_examples/semi_supervised/plot_label_propagation_digits_active_learning.html#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-digits-active-learning-py\n",
        "\n",
        "  2 - https://medium.com/@hardik.dave/active-learning-sampling-strategies-f8d8ac7037c8-\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sample</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1353</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>88</td>\n",
              "      <td>104.850</td>\n",
              "      <td>0.00727</td>\n",
              "      <td>0.443</td>\n",
              "      <td>7.997</td>\n",
              "      <td>6.990</td>\n",
              "      <td>8346.00</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.032695</td>\n",
              "      <td>0.05</td>\n",
              "      <td>C1</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.857143</td>\n",
              "      <td>306</td>\n",
              "      <td>194.175</td>\n",
              "      <td>0.03778</td>\n",
              "      <td>0.363</td>\n",
              "      <td>34.002</td>\n",
              "      <td>12.945</td>\n",
              "      <td>376.64</td>\n",
              "      <td>11.1</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>3.15</td>\n",
              "      <td>C3</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>984</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.571429</td>\n",
              "      <td>368</td>\n",
              "      <td>208.575</td>\n",
              "      <td>0.05750</td>\n",
              "      <td>0.356</td>\n",
              "      <td>46.000</td>\n",
              "      <td>13.905</td>\n",
              "      <td>451.54</td>\n",
              "      <td>13.1</td>\n",
              "      <td>0.271930</td>\n",
              "      <td>3.10</td>\n",
              "      <td>C1</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>297</td>\n",
              "      <td>175.725</td>\n",
              "      <td>0.03667</td>\n",
              "      <td>0.354</td>\n",
              "      <td>33.003</td>\n",
              "      <td>11.715</td>\n",
              "      <td>393.76</td>\n",
              "      <td>10.5</td>\n",
              "      <td>0.185008</td>\n",
              "      <td>2.85</td>\n",
              "      <td>C1</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>123</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.571429</td>\n",
              "      <td>235</td>\n",
              "      <td>225.000</td>\n",
              "      <td>2.35000</td>\n",
              "      <td>0.923</td>\n",
              "      <td>235.000</td>\n",
              "      <td>15.000</td>\n",
              "      <td>5805.82</td>\n",
              "      <td>21.7</td>\n",
              "      <td>0.187400</td>\n",
              "      <td>0.40</td>\n",
              "      <td>C4</td>\n",
              "      <td>High</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          x1  x2         x3   x4       x5       x6     x7       x8      x9  \\\n",
              "sample                                                                       \n",
              "1       1353 NaN   1.142857   88  104.850  0.00727  0.443    7.997   6.990   \n",
              "2       1107 NaN   4.857143  306  194.175  0.03778  0.363   34.002  12.945   \n",
              "3        984 NaN   6.571429  368  208.575  0.05750  0.356   46.000  13.905   \n",
              "4       1107 NaN   4.714286  297  175.725  0.03667  0.354   33.003  11.715   \n",
              "5        123 NaN  33.571429  235  225.000  2.35000  0.923  235.000  15.000   \n",
              "\n",
              "            x10   x11       x12   x13 x14     y  \n",
              "sample                                           \n",
              "1       8346.00   3.9  0.032695  0.05  C1   Low  \n",
              "2        376.64  11.1  0.210526  3.15  C3   Low  \n",
              "3        451.54  13.1  0.271930  3.10  C1   Low  \n",
              "4        393.76  10.5  0.185008  2.85  C1   Low  \n",
              "5       5805.82  21.7  0.187400  0.40  C4  High  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "SEED = 485\n",
        "np.random.seed(SEED)\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv(\"Dataset-train-vf.csv\", index_col=\"sample\")\n",
        "\n",
        "# Display the first few rows\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocess the data\n",
        "- Remove the columns with more than 50% missing values and impute the rest with mean\n",
        "- convert the categorical columns into numerical columns\n",
        "- scale the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>y</th>\n",
              "      <th>x14_C1</th>\n",
              "      <th>x14_C2</th>\n",
              "      <th>x14_C3</th>\n",
              "      <th>x14_C4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sample</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.103775</td>\n",
              "      <td>-0.646737</td>\n",
              "      <td>-0.174571</td>\n",
              "      <td>-1.558357</td>\n",
              "      <td>-0.429737</td>\n",
              "      <td>-0.051848</td>\n",
              "      <td>-0.512699</td>\n",
              "      <td>-1.558357</td>\n",
              "      <td>0.135166</td>\n",
              "      <td>-0.220630</td>\n",
              "      <td>-0.268636</td>\n",
              "      <td>-0.379805</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.153380</td>\n",
              "      <td>-0.405987</td>\n",
              "      <td>-0.152026</td>\n",
              "      <td>0.318840</td>\n",
              "      <td>-0.370081</td>\n",
              "      <td>-0.372019</td>\n",
              "      <td>-0.329673</td>\n",
              "      <td>0.318840</td>\n",
              "      <td>-0.098963</td>\n",
              "      <td>-0.183989</td>\n",
              "      <td>-0.189301</td>\n",
              "      <td>-0.095592</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.178183</td>\n",
              "      <td>-0.294872</td>\n",
              "      <td>-0.145615</td>\n",
              "      <td>0.621461</td>\n",
              "      <td>-0.331523</td>\n",
              "      <td>-0.400034</td>\n",
              "      <td>-0.245230</td>\n",
              "      <td>0.621461</td>\n",
              "      <td>-0.096762</td>\n",
              "      <td>-0.173811</td>\n",
              "      <td>-0.161907</td>\n",
              "      <td>-0.100176</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.153380</td>\n",
              "      <td>-0.415247</td>\n",
              "      <td>-0.152957</td>\n",
              "      <td>-0.068894</td>\n",
              "      <td>-0.372252</td>\n",
              "      <td>-0.408039</td>\n",
              "      <td>-0.336704</td>\n",
              "      <td>-0.068894</td>\n",
              "      <td>-0.098460</td>\n",
              "      <td>-0.187043</td>\n",
              "      <td>-0.200685</td>\n",
              "      <td>-0.123096</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.351803</td>\n",
              "      <td>1.455192</td>\n",
              "      <td>-0.159369</td>\n",
              "      <td>0.966638</td>\n",
              "      <td>4.150955</td>\n",
              "      <td>1.869182</td>\n",
              "      <td>1.084974</td>\n",
              "      <td>0.966638</td>\n",
              "      <td>0.060539</td>\n",
              "      <td>-0.130046</td>\n",
              "      <td>-0.199618</td>\n",
              "      <td>-0.347717</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              x1        x3        x4        x5        x6        x7        x8  \\\n",
              "sample                                                                         \n",
              "1      -0.103775 -0.646737 -0.174571 -1.558357 -0.429737 -0.051848 -0.512699   \n",
              "2      -0.153380 -0.405987 -0.152026  0.318840 -0.370081 -0.372019 -0.329673   \n",
              "3      -0.178183 -0.294872 -0.145615  0.621461 -0.331523 -0.400034 -0.245230   \n",
              "4      -0.153380 -0.415247 -0.152957 -0.068894 -0.372252 -0.408039 -0.336704   \n",
              "5      -0.351803  1.455192 -0.159369  0.966638  4.150955  1.869182  1.084974   \n",
              "\n",
              "              x9       x10       x11       x12       x13  y  x14_C1  x14_C2  \\\n",
              "sample                                                                        \n",
              "1      -1.558357  0.135166 -0.220630 -0.268636 -0.379805  0    True   False   \n",
              "2       0.318840 -0.098963 -0.183989 -0.189301 -0.095592  0   False   False   \n",
              "3       0.621461 -0.096762 -0.173811 -0.161907 -0.100176  0    True   False   \n",
              "4      -0.068894 -0.098460 -0.187043 -0.200685 -0.123096  0    True   False   \n",
              "5       0.966638  0.060539 -0.130046 -0.199618 -0.347717  1   False   False   \n",
              "\n",
              "        x14_C3  x14_C4  \n",
              "sample                  \n",
              "1        False   False  \n",
              "2         True   False  \n",
              "3        False   False  \n",
              "4        False   False  \n",
              "5        False    True  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x6_mean = train_data[\"x6\"].mean()\n",
        "# drop 'x2' column because it has a lot of missing values >89%\n",
        "train_data = train_data.drop([\"x2\"], axis=1)\n",
        "\n",
        "# impute missing values with the mean (x6)\n",
        "train_data[\"x6\"] = train_data[\"x6\"].fillna(train_data[\"x6\"].mean())\n",
        "\n",
        "\n",
        "# scale\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# scale all except the target column named \"y\" and the categorical column named \"x14\"\n",
        "train_data[train_data.columns.difference([\"y\", \"x14\"])] = scaler.fit_transform(\n",
        "    train_data[train_data.columns.difference([\"y\", \"x14\"])]\n",
        ")\n",
        "\n",
        "# convert categorical data to numerical data\n",
        "train_data = pd.get_dummies(train_data, columns=[\"x14\"])\n",
        "\n",
        "# map the target column to 0 and 1\n",
        "train_data[\"y\"] = train_data[\"y\"].map({\"Low\": 0, \"High\": 1})\n",
        "\n",
        "display(train_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- choose 50 random samples and keep them as labeled data, and the rest as unlabeled data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Active learning using least confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_least_confident_samples(\n",
        "    model: LogisticRegression, X_unlabeled: pd.DataFrame, n_samples: int\n",
        ") -> np.array:\n",
        "    \"\"\"\n",
        "    Query the least confident samples based on predicted probabilities.\n",
        "\n",
        "    Parameters:\n",
        "        model: Trained LogisticRegression model.\n",
        "        X_unlabeled: pd.DataFrame, unlabeled data.\n",
        "        n_samples: int, number of samples to query.\n",
        "\n",
        "    Returns:\n",
        "        least_confident_indices: np.array, indices of the least confident samples (NOTE: not the sample ID but the index in the DataFrame).\n",
        "    \"\"\"\n",
        "    # calculate probablities\n",
        "    probas = model.predict_proba(X_unlabeled)\n",
        "\n",
        "    # get the least confident samples\n",
        "    least_confident_indices = np.argsort(np.min(probas, axis=1))[:n_samples]\n",
        "\n",
        "    return least_confident_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14_C1</th>\n",
              "      <th>x14_C2</th>\n",
              "      <th>x14_C3</th>\n",
              "      <th>x14_C4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sample</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.103775</td>\n",
              "      <td>-0.646737</td>\n",
              "      <td>-0.174571</td>\n",
              "      <td>-1.558357</td>\n",
              "      <td>-0.429737</td>\n",
              "      <td>-0.051848</td>\n",
              "      <td>-0.512699</td>\n",
              "      <td>-1.558357</td>\n",
              "      <td>0.135166</td>\n",
              "      <td>-0.220630</td>\n",
              "      <td>-0.268636</td>\n",
              "      <td>-0.379805</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.153380</td>\n",
              "      <td>-0.405987</td>\n",
              "      <td>-0.152026</td>\n",
              "      <td>0.318840</td>\n",
              "      <td>-0.370081</td>\n",
              "      <td>-0.372019</td>\n",
              "      <td>-0.329673</td>\n",
              "      <td>0.318840</td>\n",
              "      <td>-0.098963</td>\n",
              "      <td>-0.183989</td>\n",
              "      <td>-0.189301</td>\n",
              "      <td>-0.095592</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.178183</td>\n",
              "      <td>-0.294872</td>\n",
              "      <td>-0.145615</td>\n",
              "      <td>0.621461</td>\n",
              "      <td>-0.331523</td>\n",
              "      <td>-0.400034</td>\n",
              "      <td>-0.245230</td>\n",
              "      <td>0.621461</td>\n",
              "      <td>-0.096762</td>\n",
              "      <td>-0.173811</td>\n",
              "      <td>-0.161907</td>\n",
              "      <td>-0.100176</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.153380</td>\n",
              "      <td>-0.415247</td>\n",
              "      <td>-0.152957</td>\n",
              "      <td>-0.068894</td>\n",
              "      <td>-0.372252</td>\n",
              "      <td>-0.408039</td>\n",
              "      <td>-0.336704</td>\n",
              "      <td>-0.068894</td>\n",
              "      <td>-0.098460</td>\n",
              "      <td>-0.187043</td>\n",
              "      <td>-0.200685</td>\n",
              "      <td>-0.123096</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.351803</td>\n",
              "      <td>1.455192</td>\n",
              "      <td>-0.159369</td>\n",
              "      <td>0.966638</td>\n",
              "      <td>4.150955</td>\n",
              "      <td>1.869182</td>\n",
              "      <td>1.084974</td>\n",
              "      <td>0.966638</td>\n",
              "      <td>0.060539</td>\n",
              "      <td>-0.130046</td>\n",
              "      <td>-0.199618</td>\n",
              "      <td>-0.347717</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              x1        x3        x4        x5        x6        x7        x8  \\\n",
              "sample                                                                         \n",
              "1      -0.103775 -0.646737 -0.174571 -1.558357 -0.429737 -0.051848 -0.512699   \n",
              "2      -0.153380 -0.405987 -0.152026  0.318840 -0.370081 -0.372019 -0.329673   \n",
              "3      -0.178183 -0.294872 -0.145615  0.621461 -0.331523 -0.400034 -0.245230   \n",
              "4      -0.153380 -0.415247 -0.152957 -0.068894 -0.372252 -0.408039 -0.336704   \n",
              "5      -0.351803  1.455192 -0.159369  0.966638  4.150955  1.869182  1.084974   \n",
              "\n",
              "              x9       x10       x11       x12       x13  x14_C1  x14_C2  \\\n",
              "sample                                                                     \n",
              "1      -1.558357  0.135166 -0.220630 -0.268636 -0.379805    True   False   \n",
              "2       0.318840 -0.098963 -0.183989 -0.189301 -0.095592   False   False   \n",
              "3       0.621461 -0.096762 -0.173811 -0.161907 -0.100176    True   False   \n",
              "4      -0.068894 -0.098460 -0.187043 -0.200685 -0.123096    True   False   \n",
              "5       0.966638  0.060539 -0.130046 -0.199618 -0.347717   False   False   \n",
              "\n",
              "        x14_C3  x14_C4  \n",
              "sample                  \n",
              "1        False   False  \n",
              "2         True   False  \n",
              "3        False   False  \n",
              "4        False   False  \n",
              "5        False    True  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# choose 50 random samples from the dataset\n",
        "# get index of the 50 random samples using pandas sample method\n",
        "\n",
        "labeled_data_train = train_data.sample(n=50, random_state=SEED)\n",
        "\n",
        "# 10 random samples for validation (not used in training) to evaluate the model\n",
        "labeled_data_validation = train_data.drop(labeled_data_train.index).sample(\n",
        "    n=10, random_state=SEED\n",
        ")\n",
        "\n",
        "\n",
        "# unlabeled data is the rest of the data\n",
        "unlabeled_data = (\n",
        "    train_data.drop(labeled_data_train.index)\n",
        "    .drop(labeled_data_validation.index)\n",
        "    .drop(\"y\", axis=1)\n",
        ")\n",
        "\n",
        "display(unlabeled_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8\n",
            "Accuracy: 0.8, Number of training samples: 51\n",
            "Accuracy: 0.8, Number of training samples: 52\n",
            "Accuracy: 0.8, Number of training samples: 53\n",
            "Accuracy: 0.8, Number of training samples: 54\n",
            "Accuracy: 0.8, Number of training samples: 55\n",
            "Accuracy: 0.8, Number of training samples: 56\n",
            "Accuracy: 0.8, Number of training samples: 57\n",
            "Accuracy: 0.8, Number of training samples: 58\n",
            "Accuracy: 0.8, Number of training samples: 59\n",
            "Accuracy: 0.8, Number of training samples: 60\n",
            "Accuracy: 0.8, Number of training samples: 61\n",
            "Accuracy: 0.8, Number of training samples: 62\n",
            "Accuracy: 0.8, Number of training samples: 63\n",
            "Accuracy: 0.8, Number of training samples: 64\n",
            "Accuracy: 0.8, Number of training samples: 65\n",
            "Accuracy: 0.9, Number of training samples: 66\n"
          ]
        }
      ],
      "source": [
        "# logistic regression\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(labeled_data_train.drop(\"y\", axis=1), labeled_data_train[\"y\"])\n",
        "\n",
        "# evaluate the model\n",
        "y_pred = log_reg.predict(labeled_data_validation.drop(\"y\", axis=1))\n",
        "accuracy = accuracy_score(labeled_data_validation[\"y\"], y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "# query the least confident samples while the accuracy on validation data is less than 0.9\n",
        "while accuracy < 0.9 and len(unlabeled_data) > 0:\n",
        "    n_samples = 1\n",
        "    least_confident_indices = query_least_confident_samples(\n",
        "        log_reg, unlabeled_data, n_samples\n",
        "    )\n",
        "\n",
        "    # get the sample IDs of the least confident samples\n",
        "    least_confident_samples = unlabeled_data.iloc[least_confident_indices].index\n",
        "\n",
        "    # get the labels of the least confident samples\n",
        "    # least_confident_labels = train_data.loc[least_confident_samples][\"y\"]\n",
        "\n",
        "    # print(\n",
        "    #    least_confident_labels\n",
        "    # )  # Observation: All the least confident samples are of class 1 (High) for now\n",
        "\n",
        "    # add the least confident samples to the labeled data\n",
        "    labeled_data_train = pd.concat(\n",
        "        [labeled_data_train, train_data.loc[least_confident_samples]]\n",
        "    )\n",
        "\n",
        "    # remove the least confident samples from the unlabeled data\n",
        "    unlabeled_data = unlabeled_data.drop(least_confident_samples)\n",
        "\n",
        "    # retrain the model\n",
        "    log_reg = LogisticRegression()\n",
        "    log_reg.fit(labeled_data_train.drop(\"y\", axis=1), labeled_data_train[\"y\"])\n",
        "\n",
        "    # evaluate the model\n",
        "    y_pred = log_reg.predict(labeled_data_validation.drop(\"y\", axis=1))\n",
        "    accuracy = accuracy_score(labeled_data_validation[\"y\"], y_pred)\n",
        "    print(\n",
        "        f\"Accuracy: {accuracy}, Number of training samples: {len(labeled_data_train)}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66 samples were used for training.\n",
            "Accuracy on the test set: 0.8814814814814815\n",
            "Confusion matrix:\n",
            "[[242  10]\n",
            " [ 38 115]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluation on the test set\n",
        "test_data = pd.read_csv(\"Dataset-test-vf.csv\", index_col=\"sample\")\n",
        "\n",
        "# drop 'x2' column because it has a lot of missing values >89%\n",
        "test_data = test_data.drop([\"x2\"], axis=1)\n",
        "\n",
        "# impute missing values with the mean (x6) from the training data\n",
        "test_data[\"x6\"] = test_data[\"x6\"].fillna(x6_mean)\n",
        "\n",
        "# scale\n",
        "test_data[test_data.columns.difference([\"y\", \"x14\"])] = scaler.transform(\n",
        "    test_data[test_data.columns.difference([\"y\", \"x14\"])]\n",
        ")\n",
        "\n",
        "# convert categorical data to numerical data\n",
        "test_data = pd.get_dummies(test_data, columns=[\"x14\"])\n",
        "\n",
        "# map the target column to 0 and 1\n",
        "test_data[\"y\"] = test_data[\"y\"].map({\"Low\": 0, \"High\": 1})\n",
        "\n",
        "# evaluate the model on the test set\n",
        "y_pred = log_reg.predict(test_data.drop(\"y\", axis=1))\n",
        "accuracy = accuracy_score(test_data[\"y\"], y_pred)\n",
        "print(f\"{len(labeled_data_train)} samples were used for training.\")\n",
        "print(f\"Accuracy on the test set: {accuracy}\")\n",
        "print(f\"Confusion matrix:\\n{confusion_matrix(test_data['y'], y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Active learning using entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_entropy_samples(\n",
        "    model: LogisticRegression, X_unlabeled: pd.DataFrame, n_samples: int\n",
        ") -> np.array:\n",
        "    \"\"\"\n",
        "    Query the samples with the highest entropy in predictions.\n",
        "\n",
        "    Parameters:\n",
        "        model: Trained LogisticRegression model.\n",
        "        X_unlabeled: pd.dataframe, feature matrix of unlabeled samples.\n",
        "        n_samples: int, number of samples to query.\n",
        "\n",
        "    Returns:\n",
        "        np.array, indices of the samples with the highest entropy. (NOTE: not the sample ID but the index in the DataFrame).\n",
        "    \"\"\"\n",
        "    # Get predicted probabilities for unlabeled data\n",
        "    probs = model.predict_proba(X_unlabeled)\n",
        "\n",
        "    # Calculate entropy for each sample\n",
        "    entropy = -np.sum(\n",
        "        probs * np.log(probs + 1e-10), axis=1\n",
        "    )  # Add 1e-10 to avoid log(0)\n",
        "\n",
        "    # Get indices of the n_samples with highest entropy\n",
        "    high_entropy_indices = np.argsort(entropy)[-n_samples:]\n",
        "\n",
        "    return high_entropy_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14_C1</th>\n",
              "      <th>x14_C2</th>\n",
              "      <th>x14_C3</th>\n",
              "      <th>x14_C4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sample</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.103775</td>\n",
              "      <td>-0.646737</td>\n",
              "      <td>-0.174571</td>\n",
              "      <td>-1.558357</td>\n",
              "      <td>-0.429737</td>\n",
              "      <td>-0.051848</td>\n",
              "      <td>-0.512699</td>\n",
              "      <td>-1.558357</td>\n",
              "      <td>0.135166</td>\n",
              "      <td>-0.220630</td>\n",
              "      <td>-0.268636</td>\n",
              "      <td>-0.379805</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.153380</td>\n",
              "      <td>-0.405987</td>\n",
              "      <td>-0.152026</td>\n",
              "      <td>0.318840</td>\n",
              "      <td>-0.370081</td>\n",
              "      <td>-0.372019</td>\n",
              "      <td>-0.329673</td>\n",
              "      <td>0.318840</td>\n",
              "      <td>-0.098963</td>\n",
              "      <td>-0.183989</td>\n",
              "      <td>-0.189301</td>\n",
              "      <td>-0.095592</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.178183</td>\n",
              "      <td>-0.294872</td>\n",
              "      <td>-0.145615</td>\n",
              "      <td>0.621461</td>\n",
              "      <td>-0.331523</td>\n",
              "      <td>-0.400034</td>\n",
              "      <td>-0.245230</td>\n",
              "      <td>0.621461</td>\n",
              "      <td>-0.096762</td>\n",
              "      <td>-0.173811</td>\n",
              "      <td>-0.161907</td>\n",
              "      <td>-0.100176</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.153380</td>\n",
              "      <td>-0.415247</td>\n",
              "      <td>-0.152957</td>\n",
              "      <td>-0.068894</td>\n",
              "      <td>-0.372252</td>\n",
              "      <td>-0.408039</td>\n",
              "      <td>-0.336704</td>\n",
              "      <td>-0.068894</td>\n",
              "      <td>-0.098460</td>\n",
              "      <td>-0.187043</td>\n",
              "      <td>-0.200685</td>\n",
              "      <td>-0.123096</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.351803</td>\n",
              "      <td>1.455192</td>\n",
              "      <td>-0.159369</td>\n",
              "      <td>0.966638</td>\n",
              "      <td>4.150955</td>\n",
              "      <td>1.869182</td>\n",
              "      <td>1.084974</td>\n",
              "      <td>0.966638</td>\n",
              "      <td>0.060539</td>\n",
              "      <td>-0.130046</td>\n",
              "      <td>-0.199618</td>\n",
              "      <td>-0.347717</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              x1        x3        x4        x5        x6        x7        x8  \\\n",
              "sample                                                                         \n",
              "1      -0.103775 -0.646737 -0.174571 -1.558357 -0.429737 -0.051848 -0.512699   \n",
              "2      -0.153380 -0.405987 -0.152026  0.318840 -0.370081 -0.372019 -0.329673   \n",
              "3      -0.178183 -0.294872 -0.145615  0.621461 -0.331523 -0.400034 -0.245230   \n",
              "4      -0.153380 -0.415247 -0.152957 -0.068894 -0.372252 -0.408039 -0.336704   \n",
              "5      -0.351803  1.455192 -0.159369  0.966638  4.150955  1.869182  1.084974   \n",
              "\n",
              "              x9       x10       x11       x12       x13  x14_C1  x14_C2  \\\n",
              "sample                                                                     \n",
              "1      -1.558357  0.135166 -0.220630 -0.268636 -0.379805    True   False   \n",
              "2       0.318840 -0.098963 -0.183989 -0.189301 -0.095592   False   False   \n",
              "3       0.621461 -0.096762 -0.173811 -0.161907 -0.100176    True   False   \n",
              "4      -0.068894 -0.098460 -0.187043 -0.200685 -0.123096    True   False   \n",
              "5       0.966638  0.060539 -0.130046 -0.199618 -0.347717   False   False   \n",
              "\n",
              "        x14_C3  x14_C4  \n",
              "sample                  \n",
              "1        False   False  \n",
              "2         True   False  \n",
              "3        False   False  \n",
              "4        False   False  \n",
              "5        False    True  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# choose 50 random samples from the dataset\n",
        "# get index of the 50 random samples using pandas sample method\n",
        "\n",
        "labeled_data_train = train_data.sample(n=50, random_state=SEED)\n",
        "\n",
        "# 10 random samples for validation (not used in training) to evaluate the model\n",
        "labeled_data_validation = train_data.drop(labeled_data_train.index).sample(\n",
        "    n=10, random_state=SEED\n",
        ")\n",
        "\n",
        "\n",
        "# unlabeled data is the rest of the data\n",
        "unlabeled_data = (\n",
        "    train_data.drop(labeled_data_train.index)\n",
        "    .drop(labeled_data_validation.index)\n",
        "    .drop(\"y\", axis=1)\n",
        ")\n",
        "\n",
        "display(unlabeled_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8\n",
            "Accuracy: 0.9, Number of training samples: 51\n"
          ]
        }
      ],
      "source": [
        "# logistic regression\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(labeled_data_train.drop(\"y\", axis=1), labeled_data_train[\"y\"])\n",
        "\n",
        "# evaluate the model\n",
        "y_pred = log_reg.predict(labeled_data_validation.drop(\"y\", axis=1))\n",
        "accuracy = accuracy_score(labeled_data_validation[\"y\"], y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "# query the most entropic samples while the accuracy on validation data is less than 0.9, and retrain the model\n",
        "while accuracy < 0.9 and len(unlabeled_data) > 0:\n",
        "    n_samples = 1\n",
        "    most_entropic_indices = query_entropy_samples(log_reg, unlabeled_data, n_samples)\n",
        "\n",
        "    # get the sample IDs of the most entropic samples\n",
        "    most_entropic_samples = unlabeled_data.iloc[most_entropic_indices].index\n",
        "\n",
        "    # get the labels of the most entropic samples\n",
        "    # most_entropic_labels = train_data.loc[most_entropic_sample][\"y\"]\n",
        "    # print(\n",
        "    #    most_entropic_labels\n",
        "    # )  # Observation: All the samples are of class 1 (High)\n",
        "\n",
        "    # add the most entropic sample to the labeled data\n",
        "    labeled_data_train = pd.concat(\n",
        "        [labeled_data_train, train_data.loc[most_entropic_samples]]\n",
        "    )\n",
        "\n",
        "    # remove the most entropic samples from the unlabeled data\n",
        "    unlabeled_data = unlabeled_data.drop(most_entropic_samples)\n",
        "\n",
        "    # retrain the model\n",
        "    log_reg = LogisticRegression()\n",
        "    log_reg.fit(labeled_data_train.drop(\"y\", axis=1), labeled_data_train[\"y\"])\n",
        "\n",
        "    # evaluate the model\n",
        "    y_pred = log_reg.predict(labeled_data_validation.drop(\"y\", axis=1))\n",
        "    accuracy = accuracy_score(labeled_data_validation[\"y\"], y_pred)\n",
        "    print(\n",
        "        f\"Accuracy: {accuracy}, Number of training samples: {len(labeled_data_train)}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51 samples were used for training.\n",
            "Accuracy on the test set: 0.8790123456790123\n",
            "Confusion matrix:\n",
            "[[242  10]\n",
            " [ 39 114]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluation on the test set\n",
        "test_data = pd.read_csv(\"Dataset-test-vf.csv\", index_col=\"sample\")\n",
        "\n",
        "# drop 'x2' column because it has a lot of missing values >89%\n",
        "test_data = test_data.drop([\"x2\"], axis=1)\n",
        "\n",
        "# impute missing values with the mean (x6) from the training data\n",
        "test_data[\"x6\"] = test_data[\"x6\"].fillna(x6_mean)\n",
        "\n",
        "# scale\n",
        "test_data[test_data.columns.difference([\"y\", \"x14\"])] = scaler.transform(\n",
        "    test_data[test_data.columns.difference([\"y\", \"x14\"])]\n",
        ")\n",
        "\n",
        "# convert categorical data to numerical data\n",
        "test_data = pd.get_dummies(test_data, columns=[\"x14\"])\n",
        "\n",
        "# map the target column to 0 and 1\n",
        "test_data[\"y\"] = test_data[\"y\"].map({\"Low\": 0, \"High\": 1})\n",
        "\n",
        "# evaluate the model on the test set\n",
        "y_pred = log_reg.predict(test_data.drop(\"y\", axis=1))\n",
        "accuracy = accuracy_score(test_data[\"y\"], y_pred)\n",
        "print(f\"{len(labeled_data_train)} samples were used for training.\")\n",
        "print(f\"Accuracy on the test set: {accuracy}\")\n",
        "print(f\"Confusion matrix:\\n{confusion_matrix(test_data['y'], y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using active learning, we trained the model with two strategies: least confidence and entropy sampling. The test accuracy achieved with these methods was  approximately 0.881 and 0.879, respectively. In the least confidence approach, the model required 66 labeled samples, while the entropy method used only 51 labeled samples to reach a similar performance level. stunning :))\n",
        "\n",
        "# This demonstrates the effectiveness of active learning in significantly reducing the amount of labeled data needed to train a model. Additionally, the entropy-based strategy highlights its strength in identifying and selecting the most informative samples for labeling, making the learning process more efficient."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
